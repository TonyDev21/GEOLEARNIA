#importar librerias
from flask import Flask, render_template, Response
import cv2
import numpy as np
import tensorflow as tf

# Cargar el modelo preentrenado de figuras geom√©tricas
model = tf.keras.models.load_model("FigurasGeometricas.h5")

# Lista de clases
clases = ['Circulo', 'Cuadrado', 'Triangulo']

#Realizar videocaptura
cap = None
# Variables globales
cap = None
camera_error = None

try:
    print("üîç Intentando acceder a la c√°mara...")
    
    # Probar diferentes backends y configuraciones
    backends = [
        (cv2.CAP_DSHOW, "DirectShow"),
        (cv2.CAP_MSMF, "Media Foundation"),
        (cv2.CAP_ANY, "Auto-detect")
    ]
    
    for backend_id, backend_name in backends:
        try:
            print(f"   Probando backend: {backend_name}")
            test_cap = cv2.VideoCapture(0, backend_id)
            
            if test_cap.isOpened():
                # Configurar propiedades
                test_cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                test_cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                test_cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                
                # Intentar leer un frame
                ret, test_frame = test_cap.read()
                
                if ret and test_frame is not None:
                    print(f"‚úÖ C√°mara inicializada correctamente con {backend_name}")
                    print(f"   Resoluci√≥n: {test_frame.shape}")
                    cap = test_cap
                    break
                else:
                    print(f"‚ö†Ô∏è  {backend_name}: C√°mara abierta pero sin frames")
                    test_cap.release()
            else:
                print(f"‚ùå {backend_name}: No se pudo abrir la c√°mara")
                test_cap.release()
                
        except Exception as e:
            print(f"‚ùå Error con {backend_name}: {e}")
            if 'test_cap' in locals():
                test_cap.release()
    
    if cap is None:
        camera_error = "No se pudo inicializar la c√°mara con ning√∫n backend"
        print(f"‚ö†Ô∏è  {camera_error}")
        print("   La aplicaci√≥n funcionar√° sin video en tiempo real")
        
except Exception as e:
    camera_error = f"Error general al acceder a la c√°mara: {e}"
    print(f"‚ùå {camera_error}")
    print("   La aplicaci√≥n funcionar√° sin video en tiempo real")

# Funci√≥n para realizar la predicci√≥n con el modelo
def predict_shape(frame, model):
    # Redimensionar el fotograma al tama√±o esperado por el modelo
    resized_frame = cv2.resize(frame, (200, 200)) 
    # Normalizar el fotograma
    normalized_frame = resized_frame / 255.0 
    # Hacer la predicci√≥n
    predictions = model.predict(np.expand_dims(normalized_frame, axis=0))
    # Obtener el √≠ndice de la clase con mayor probabilidad
    predicted_class_idx = np.argmax(predictions[0]) 
    # Obtener el nombre de la clase predicha
    predicted_class = clases[predicted_class_idx]
    
    return predicted_class

# Funci√≥n para realizar la predicci√≥n con detecci√≥n visual
def predict_shape_with_detection(frame, model):
    # Crear una copia del frame para dibujar
    display_frame = frame.copy()
    
    # Convertir a escala de grises para detecci√≥n de contornos
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # Aplicar desenfoque para reducir ruido
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # Detectar bordes
    edges = cv2.Canny(blurred, 50, 150)
    
    # Encontrar contornos
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Realizar predicci√≥n con el modelo
    resized_frame = cv2.resize(frame, (200, 200))
    normalized_frame = resized_frame / 255.0
    predictions = model.predict(np.expand_dims(normalized_frame, axis=0))
    predicted_class_idx = np.argmax(predictions[0])
    predicted_class = clases[predicted_class_idx]
    confidence = predictions[0][predicted_class_idx] * 100
    
    # Encontrar el contorno m√°s grande (probablemente la figura principal)
    if contours:
        # Filtrar contornos por √°rea m√≠nima
        min_area = 500
        valid_contours = [c for c in contours if cv2.contourArea(c) > min_area]
        
        if valid_contours:
            # Obtener el contorno m√°s grande
            largest_contour = max(valid_contours, key=cv2.contourArea)
            
            # Dibujar el contorno
            cv2.drawContours(display_frame, [largest_contour], -1, (0, 255, 0), 3)
            
            # Obtener el rect√°ngulo delimitador
            x, y, w, h = cv2.boundingRect(largest_contour)
            
            # Dibujar rect√°ngulo delimitador
            cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
            
            # Calcular centro del contorno
            M = cv2.moments(largest_contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                
                # Dibujar punto central
                cv2.circle(display_frame, (cx, cy), 8, (0, 0, 255), -1)
                
                # Dibujar flecha apuntando al centro
                cv2.arrowedLine(display_frame, (cx - 50, cy - 50), (cx - 10, cy - 10), (0, 255, 255), 3)
                
                # Mostrar texto con la predicci√≥n cerca del objeto
                label_text = f"{predicted_class} ({confidence:.1f}%)"
                text_x = max(x, 10)
                text_y = max(y - 10, 30)
                
                # Fondo para el texto
                (text_width, text_height), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
                cv2.rectangle(display_frame, (text_x - 5, text_y - text_height - 5), 
                            (text_x + text_width + 5, text_y + 5), (0, 0, 0), -1)
                
                # Texto de predicci√≥n
                cv2.putText(display_frame, label_text, (text_x, text_y), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    
    # Mostrar informaci√≥n general en la esquina superior
    info_text = f"Detectando: {predicted_class}"
    cv2.putText(display_frame, info_text, (10, 30), 
              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    # Mostrar instrucciones
    cv2.putText(display_frame, "Coloca una figura geometrica frente a la camara", (10, display_frame.shape[0] - 15), 
              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
    
    return predicted_class, display_frame

# Funci√≥n SIMPLE para generar frames sin detecci√≥n compleja
def generar_frames():
    global cap
    
    print("üé• generar_frames() SIMPLE llamada")
    print(f"üì∑ Estado de cap: {cap}")
    
    if cap is None or not cap.isOpened():
        # Sin c√°mara - imagen de error simple
        print("‚ùå C√°mara no disponible - enviando imagen de error")
        error_frame = np.zeros((480, 640, 3), dtype=np.uint8)
        cv2.putText(error_frame, "CAMARA NO DISPONIBLE", (120, 200), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(error_frame, "Verifica la conexion", (150, 250), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        success, buffer = cv2.imencode('.jpg', error_frame)
        if success:
            frame_bytes = buffer.tobytes()
            while True:
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
                import time
                time.sleep(1)
    else:
        # Con c√°mara - stream simple sin detecci√≥n compleja
        print("‚úÖ Iniciando stream SIMPLE")
        frame_count = 0
        
        while True:
            try:
                ret, frame = cap.read()
                
                if not ret:
                    print(f"‚ùå Error leyendo frame {frame_count + 1}")
                    break
                
                frame_count += 1
                
                # Log cada 30 frames
                if frame_count == 1 or frame_count % 30 == 0:
                    print(f"üìπ Frame {frame_count} - Sum: {np.sum(frame)}")
                
                # Verificar que el frame no est√© completamente negro
                if np.sum(frame) == 0:
                    print(f"‚ö†Ô∏è  Frame {frame_count} est√° completamente negro")
                    continue
                
                # Hacer predicci√≥n SIMPLE
                try:
                    resized_frame = cv2.resize(frame, (200, 200))
                    normalized_frame = resized_frame / 255.0
                    predictions = model.predict(np.expand_dims(normalized_frame, axis=0))
                    predicted_class_idx = np.argmax(predictions[0])
                    predicted_class = clases[predicted_class_idx]
                    confidence = predictions[0][predicted_class_idx] * 100
                    
                    # Agregar SOLO texto simple
                    cv2.putText(frame, f"Figura: {predicted_class} ({confidence:.1f}%)", 
                              (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                    
                    cv2.putText(frame, "Coloca una figura frente a la camara", 
                              (10, frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è  Error en predicci√≥n: {e}")
                    cv2.putText(frame, "Detectando...", (10, 30), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
                
                # Codificar como JPEG con buena calidad
                success, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 90])
                
                if not success:
                    print(f"‚ùå Error codificando frame {frame_count}")
                    continue
                
                frame_bytes = buffer.tobytes()
                
                # Log del primer frame
                if frame_count == 1:
                    print(f"‚úÖ Primer frame OK - {len(frame_bytes)} bytes")
                
                # Enviar frame
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
                
            except Exception as e:
                print(f"‚ùå Error en loop: {e}")
                break
        
        # Crear imagen de placeholder
        img = Image.new('RGB', (640, 480), color=(60, 60, 60))
        draw = ImageDraw.Draw(img)
        
        # Texto informativo
        text_lines = [
            "C√ÅMARA NO DISPONIBLE",
            "",
            "Por favor verifica:",
            "‚Ä¢ Que la c√°mara est√© conectada",
            "‚Ä¢ Permisos de c√°mara habilitados",
            "‚Ä¢ Ninguna otra app use la c√°mara"
        ]
        
        y_position = 150
        for line in text_lines:
            draw.text((50, y_position), line, fill=(255, 255, 255))
            y_position += 30
        
        # Convertir a bytes
        img_buffer = io.BytesIO()
        img.save(img_buffer, format='JPEG')
        frame_bytes = img_buffer.getvalue()
        
        while True:
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            import time
            time.sleep(1)  # Actualizar cada segundo
    else:
        # Con c√°mara - funcionamiento normal
        print("‚úÖ Iniciando stream de video con c√°mara")
        print(f"üìπ Verificando c√°mara antes del loop...")
        
        # Test de lectura inicial
        test_ret, test_frame = cap.read()
        if not test_ret:
            print("‚ùå PROBLEMA: No se puede leer de la c√°mara en el primer intento")
            print("üîÑ Intentando reinicializar la c√°mara...")
            cap.release()
            import time
            time.sleep(0.5)
            cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
            test_ret, test_frame = cap.read()
            
        if test_ret:
            print(f"‚úÖ C√°mara OK - Frame size: {test_frame.shape}")
        else:
            print("‚ùå CR√çTICO: C√°mara no responde despu√©s de reinicializaci√≥n")
            
        frame_count = 0
        
        while True:
            try:
                ret, frame = cap.read()
                if not ret:
                    print(f"‚ùå No se pudo leer frame de la c√°mara (intento {frame_count + 1})")
                    # Intentar reconectarse
                    if frame_count == 0:
                        print("üîÑ Intentando reconectar c√°mara...")
                        cap.release()
                        import time
                        time.sleep(1)
                        cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
                        continue
                    else:
                        print("‚ùå C√°mara perdida durante streaming")
                        break
                
                frame_count += 1
                if frame_count == 1:
                    print(f"üéâ ¬°PRIMER FRAME LE√çDO EXITOSAMENTE! Size: {frame.shape}")
                if frame_count % 30 == 0:  # Log cada 30 frames (~1 segundo)
                    print(f"üìπ Frame {frame_count} procesado exitosamente")
                
                # Realizar predicci√≥n y detecci√≥n visual
                try:
                    predicted_class, detection_frame = predict_shape_with_detection(frame, model)
                    frame = detection_frame  # Usar el frame con la detecci√≥n visual
                    
                except Exception as e:
                    print(f"‚ùå Error en predicci√≥n: {e}")
                    cv2.putText(frame, "Error en prediccion", 
                              (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                
                # Codificar frame como JPEG
                try:
                    success, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
                    if not success:
                        print("‚ùå Error al codificar frame como JPEG")
                        continue
                        
                    frame_bytes = buffer.tobytes()
                    if frame_count == 1:
                        print(f"‚úÖ Frame codificado - Tama√±o: {len(frame_bytes)} bytes")

                    yield (b'--frame\r\n'
                           b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
                           
                except Exception as e:
                    print(f"‚ùå Error al codificar/enviar frame: {e}")
                    continue
                       
            except Exception as e:
                print(f"‚ùå Error en el loop de video: {e}")
                import traceback
                traceback.print_exc()
                break

#Crear la app
app = Flask(__name__)

#Ruta principal
@app.route('/')
def index():
    print("üåê Acceso a p√°gina principal")
    return render_template('index.html')

@app.route('/test')
def test():
    print("üß™ Acceso a p√°gina de test simple")
    return render_template('test_simple.html')

@app.route('/video')
def video():
    print("üìπ Solicitando stream de video")
    print(f"üì∑ Estado de c√°mara en /video: cap={cap}, isOpened={cap.isOpened() if cap else 'N/A'}")
    try:
        response = Response(generar_frames(), 
                       mimetype='multipart/x-mixed-replace; boundary=frame')
        print("‚úÖ Response de video creada exitosamente")
        return response
    except Exception as e:
        print(f"‚ùå Error en ruta de video: {e}")
        import traceback
        traceback.print_exc()
        return f"Error en stream de video: {e}", 500

#Ejecutar
if __name__=='__main__':
    print("üéì GEOLEARNIA - Aplicaci√≥n Web")
    print("================================")
    print("üåê Servidor Flask iniciando...")
    print(f"üì± URL: http://127.0.0.1:5001")
    if cap and cap.isOpened():
        print("üì∑ Estado de c√°mara: ‚úÖ Disponible")
    else:
        print("üì∑ Estado de c√°mara: ‚ö†Ô∏è  No disponible")
        if camera_error:
            print(f"   Error: {camera_error}")
    print("ü§ñ TensorFlow cargado exitosamente")
    print("================================")
    app.run(debug=True, port=5001, host='127.0.0.1')

#Ruta para vizualizar el modulo 1 en la web: http://127.0.0.1:5000/